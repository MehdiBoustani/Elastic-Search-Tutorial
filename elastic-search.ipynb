{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Elastic Search\n",
    "\n",
    "**Mehdi Boustani** - S221594  \n",
    "**Nicolas Schneiders** - S203005  \n",
    "**Maxim Piron** - S211493  \n",
    "**Andreas Stistrup** - S212891  \n",
    "\n",
    "*Faculty of Applied Sciences, University of Liège*\n",
    "\n",
    "April 28, 2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation & configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Elasticsearch\n",
    "If you don't have Docker installed yet, you can download and install it from the [official website](https://www.docker.com/). \n",
    "\n",
    "Once Docker is running on your machine, launch Elasticsearch using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6e8d9e503ed51e177bb6b93c550e7ee43267a799af30045ca21d550d8a07d664\n"
     ]
    }
   ],
   "source": [
    "!docker run -p 127.0.0.1:9200:9200 -d --name elasticsearch \\\n",
    "  -e \"discovery.type=single-node\" \\\n",
    "  -e \"xpack.security.enabled=false\" \\\n",
    "  -e \"xpack.license.self_generated.type=trial\" \\\n",
    "  -v \"elasticsearch-data:/usr/share/elasticsearch/data\" \\\n",
    "  docker.elastic.co/elasticsearch/elasticsearch:8.15.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies  \n",
    "Let's install all the necessary Python packages we'll be using throughout this tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in /home/zenixtu/.local/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: elasticsearch==8.15.0 in /home/zenixtu/.local/lib/python3.10/site-packages (8.15.0)\n",
      "Requirement already satisfied: pandas in /home/zenixtu/.local/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /home/zenixtu/.local/lib/python3.10/site-packages (3.7.0)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.13 in /home/zenixtu/.local/lib/python3.10/site-packages (from elasticsearch==8.15.0) (8.17.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zenixtu/.local/lib/python3.10/site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests) (1.26.5)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/zenixtu/.local/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/zenixtu/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/zenixtu/.local/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/lib/python3/dist-packages (from matplotlib) (4.29.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/lib/python3/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/zenixtu/.local/lib/python3.10/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zenixtu/.local/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# requests       → to interact with the Elasticsearch REST API\n",
    "# elasticsearch  → official Elasticsearch Python client\n",
    "# pandas         → for handling and analyzing tabular data (e.g., dataset exploration)\n",
    "# matplotlib     → for optional data visualization (e.g., query stats or aggregations)\n",
    "\n",
    "!pip install requests elasticsearch==8.15.0 pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to ElasticSearch !\n",
      "{'cluster_name': 'docker-cluster',\n",
      " 'cluster_uuid': 'sY43eXx2R5C_MHq1iRpKKQ',\n",
      " 'name': '6e8d9e503ed5',\n",
      " 'tagline': 'You Know, for Search',\n",
      " 'version': {'build_date': '2024-08-05T10:05:34.233336849Z',\n",
      "             'build_flavor': 'default',\n",
      "             'build_hash': '1a77947f34deddb41af25e6f0ddb8e830159c179',\n",
      "             'build_snapshot': False,\n",
      "             'build_type': 'docker',\n",
      "             'lucene_version': '9.11.1',\n",
      "             'minimum_index_compatibility_version': '7.0.0',\n",
      "             'minimum_wire_compatibility_version': '7.17.0',\n",
      "             'number': '8.15.0'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "es = Elasticsearch('http://localhost:9200')\n",
    "info = es.info()\n",
    "\n",
    "print('Connected to ElasticSearch !')\n",
    "pprint(info.body)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data with the bulk api\n",
    "\n",
    "To efficiently load a large dataset into Elasticsearch, we use the Bulk API. This method allows us to insert multiple documents in a single request, which is much faster and more efficient than indexing documents one by one. In this example, we will import the contents of our `apod.json` file—where each element is a document—into a new index called `apod`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulk import terminé !\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"apod.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Prepare the actions for the bulk\n",
    "actions = [\n",
    "    {\n",
    "        \"_index\": \"apod\",\n",
    "        \"_id\": doc[\"title\"], # We use the title as index since it is a unique field\n",
    "        \"_source\": doc\n",
    "    }\n",
    "    for doc in data\n",
    "]\n",
    "\n",
    "# We import the data in bulk\n",
    "try:\n",
    "    helpers.bulk(es, actions)\n",
    "    print(\"Bulk import terminé !\")\n",
    "except  Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic queries in ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elasticsearch exposes a RESTful API, which means you interact with it using standard HTTP methods. Here are the most common operations:\n",
    "\n",
    "- **GET**: Read a document or perform a search\n",
    "- **POST**: Add a new document\n",
    "- **PUT**: Create or replace a document or an index\n",
    "- **DELETE**: Remove a document or an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '2024-09-20', 'title': 'A Hazy Harvest Moon', 'explanation': \"Explanation: For northern hemisphere dwellers, September's Full Moon was the Harvest Moon. On September 17/18 the sunlit lunar nearside passed into shadow, just grazing Earth's umbra, the planet's dark, central shadow cone, in a partial lunar eclipse. Over the two and a half hours before dawn a camera fixed to a tripod was used to record this series of exposures as the eclipsed Harvest Moon set behind Spiš Castle in the hazy morning sky over eastern Slovakia. Famed in festival, story, and song, Harvest Moon is just the traditional name of the full moon nearest the autumnal equinox. According to lore the name is a fitting one. Despite the diminishing daylight hours as the growing season drew to a close, farmers could harvest crops by the light of a full moon shining on from dusk to dawn. This September's Harvest Moon was also known to some as a supermoon, a term becoming a traditional name for a full moon near perigee.\", 'image_url': 'https://apod.nasa.gov/apod/image/2409/2024_09_18_ZM_Spis_50mm-Pano_Postupka_1024c.png', 'authors': 'Petr Horálek, Institute of Physics in Opava\\n'}\n"
     ]
    }
   ],
   "source": [
    "doc = es.get(index=\"apod\", id=\"A Hazy Harvest Moon\")\n",
    "print(doc['_source'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a id=\"freecodecamp\"></a> [Elasticsearch Course for Beginners - FreeCodeCamp](https://www.youtube.com/watch?v=a4HBKEda_F8&ab_channel=freeCodeCamp.org)\n",
    "\n",
    "2. <a id=\"elasticdoc\"></a> [Elastic Official Documentation](https://www.elastic.co/docs/get-started)\n",
    "\n",
    "3. <a id=\"elasticlab\"></a> [Elastic Search Lab - Tutorials](https://www.elastic.co/search-labs/tutorials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and Work Distribution\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
