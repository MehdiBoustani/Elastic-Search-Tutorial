{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Elastic Search\n",
    "\n",
    "**Mehdi Boustani** - S221594  \n",
    "**Nicolas Schneiders** - S203005  \n",
    "**Maxim Piron** - S211493  \n",
    "**Andreas Stistrup** - S212891  \n",
    "\n",
    "*Faculty of Applied Sciences, University of Liège*\n",
    "\n",
    "April 28, 2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation & configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Elasticsearch\n",
    "If you don't have Docker installed yet, you can download and install it from the [official website](https://www.docker.com/). \n",
    "\n",
    "Once Docker is running on your machine, launch Elasticsearch using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -p 127.0.0.1:9200:9200 -d --name elasticsearch \\\n",
    "  -e \"discovery.type=single-node\" \\\n",
    "  -e \"xpack.security.enabled=false\" \\\n",
    "  -e \"xpack.license.self_generated.type=trial\" \\\n",
    "  -v \"elasticsearch-data:/usr/share/elasticsearch/data\" \\\n",
    "  docker.elastic.co/elasticsearch/elasticsearch:8.15.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies  \n",
    "Let's install all the necessary Python packages we'll be using throughout this tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests       → to interact with the Elasticsearch REST API\n",
    "# elasticsearch  → official Elasticsearch Python client\n",
    "# pandas         → for handling and analyzing tabular data (e.g., dataset exploration)\n",
    "# matplotlib     → for optional data visualization (e.g., query stats or aggregations)\n",
    "\n",
    "!pip install requests elasticsearch==8.15.0 pandas matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "es = Elasticsearch('http://localhost:9200')\n",
    "info = es.info()\n",
    "\n",
    "print('Connected to ElasticSearch !')\n",
    "pprint(info.body)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data with the bulk api\n",
    "\n",
    "To efficiently load a large dataset into Elasticsearch, we use the Bulk API. This method allows us to insert multiple documents in a single request, which is much faster and more efficient than indexing documents one by one. In this example, we will import the contents of our `apod.json` file—where each element is a document—into a new index called `apod`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"apod.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Prepare the actions for the bulk\n",
    "actions = [\n",
    "    {\n",
    "        \"_index\": \"apod\",\n",
    "        \"_id\": doc[\"title\"], # We use the title as index since it is a unique field (the unicity is important!)\n",
    "        \"_source\": doc\n",
    "    }\n",
    "    for doc in data\n",
    "]\n",
    "\n",
    "# We import the data in bulk\n",
    "try:\n",
    "    helpers.bulk(es, actions)\n",
    "    print(\"Bulk import terminé !\")\n",
    "except  Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic queries in ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elasticsearch exposes a RESTful API, which means you interact with it using standard HTTP methods. Here are the most common operations:\n",
    "\n",
    "- **GET**: Read a document or perform a search\n",
    "- **POST**: Add a new document\n",
    "- **PUT**: Create or replace a document or an index\n",
    "- **DELETE**: Remove a document or an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET method\n",
    "\n",
    "The GET method is used to retrieve data from our json file by providing an id. If the document with the specified id doesn't exist, it throws an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    doc = es.get(index=\"apod\", id=\"A Hazy Harvest Moon\")\n",
    "    pprint(doc['_source'])\n",
    "\n",
    "except:\n",
    "    print(\"A document with this id doesn't exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST method\n",
    "\n",
    "The POST method is used to create a new document. When using the index() method without specifying an id, elasticsearch automatically generates one (not the title as the other documents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "new_id = \"A New APOD\"\n",
    "\n",
    "new_doc = {\n",
    "    \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"title\": new_id,\n",
    "    \"explanation\": \"This is a new document added via POST.\",\n",
    "    \"image_url\": \"https://apod.nasa.gov/apod/image/2410/new_apod.jpg\",\n",
    "    \"authors\": \"Mehdi Boustani\"\n",
    "}\n",
    "\n",
    "res = es.index(index=\"apod\", document=new_doc)\n",
    "\n",
    "print(\"Document added successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PUT method\n",
    "\n",
    "The PUT method is used to create or replace a document at a specified id. If a document with that id already exists, it will be overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_id = \"Replaced APOD\"\n",
    "\n",
    "doc = {\n",
    "    \"date\": \"2024-10-02\",\n",
    "    \"title\": replaced_id,\n",
    "    \"explanation\": \"This document replaces any previous one with the same ID.\",\n",
    "    \"image_url\": \"https://apod.nasa.gov/apod/image/2410/new_apod.jpg\",\n",
    "    \"authors\": \"Mehdi Boustani\"\n",
    "}\n",
    "\n",
    "# Let's replace our previously created document\n",
    "es.index(index=\"apod\", id=new_id, document=doc)\n",
    "\n",
    "# Since we use personnalized id, let's replace it manually\n",
    "es.index(index=\"apod\", id=replaced_id, document=doc)\n",
    "\n",
    "print(f\"Document with id '{new_id}' replaced by a new document with id '{replaced_id}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DELETE method\n",
    "\n",
    "This method is used to delete a document by its id. The id must be known and specified in the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    es.delete(index=\"apod\", id=replaced_id)\n",
    "    print(f\"Document with ID {replaced_id} deleted.\")\n",
    "\n",
    "except:\n",
    "    print(\"The specified document to delete doesn't exist\")\n",
    "\n",
    "# Delete the entire index (Attention: this is irreversible!)\n",
    "# es.indices.delete(index=\"apod\")\n",
    "# print(\"Index 'apod' deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPL vs SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elasticsearch doesn't use traditional SQL language to query data, but rather a **DSL (Domain Specific Language)** based on JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main differencies\n",
    "\n",
    "1. **Query Structure**\n",
    "   - **SQL**: Uses a strict syntax with clauses like `SELECT`, `FROM`, `WHERE`\n",
    "   - **DSL**: Uses a nested JSON format, offering more flexibility in how queries are expressed\n",
    "\n",
    "2. **Search Types**\n",
    "   - **SQL**: Focuses mainly on exact matches\n",
    "   - **DSL**: Supports advanced search techniques like full-text search, fuzzy matching, and range queries\n",
    "\n",
    "Let's explore practical examples comparing SQL concepts with Elasticsearch's DSL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full-text search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"title\": \"moon\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=\"apod\", body=query)\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SQL equivalent:** `SELECT * FROM apod WHERE title LIKE '%moon%'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact match with term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"term\": {\n",
    "            \"title.keyword\": {\n",
    "                \"value\": \"A Hazy Harvest Moon\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=\"apod\", body=query)\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_source\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SQL equivalent:** `SELECT * FROM apod WHERE title = 'A Hazy Harvest Moon'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Range Query (Numeric/date filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We filter documents by a date range\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"range\": {\n",
    "            \"date\": {\n",
    "                \"gte\": \"2020-01-01\",\n",
    "                \"lte\": \"2020-12-31\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=\"apod\", body=query)\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_source\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SQL equivalent:** `SELECT * FROM apod WHERE date BETWEEN '2020-01-01' AND '2020-12-31'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy Query (Typo-tolerant search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typo-tolerant search with fuzzy\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"fuzzy\": {\n",
    "            \"title\": {\n",
    "                \"value\": \"Galaxy\",\n",
    "                \"fuzziness\": \"AUTO\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=\"apod\", body=query)\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SQL equivalent:** No direct equivalent, similar to a `LIKE` with typos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic search as a search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of Elasticsearch is to empower client workflows to retrieve data from your database using powerful, flexible queries. To customize search behavior, Elasticsearch offers several fine-tuning parameters. In this section, we’ll explore the filter, must, must_not, and should clauses.\n",
    "\n",
    "A key concept here is document scoring. When you run a query, Elasticsearch calculates a relevance score for each candidate document and orders results accordingly. You then return the top n documents based on that ranking. To further control how scores influence ordering, you can use the boost parameter to adjust relevance and achieve custom ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you apply a filter criterion to your query, you define one or more clauses that documents must satisfy to be included. Filters are score-neutral, they don’t alter a document’s relevance score, they only prune out non-matching hits. Below we’ll explore a selection of the most common filter clauses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "index_name = \"apod\"\n",
    "\n",
    "# This query will filter out documents that do not match the date \"2024-09-27\"\n",
    "term_query = {\n",
    "    \"term\": {\"date\": \"2024-09-27\"}\n",
    "}\n",
    "\n",
    "# This query will filter documents with a date between \"2024-09-09\" and \"2024-09-30\"\n",
    "range_query = {\n",
    "    \"range\": {\n",
    "        \"date\": {\"gte\": \"2024-09-09\", \"lte\": \"2024-09-30\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# This query will filter documents that have a non-null value for the field \"image_url\"\n",
    "exists_query = {\n",
    "    \"exists\": {\"field\": \"note\"}\n",
    "}\n",
    "\n",
    "# This query will filter documents that have the exact term \"David Martinez Delgado et al.\" in the \"authors\" field\n",
    "term_authors_query = {\n",
    "    \"term\": {\"authors.keyword\": \"David Martinez Delgado et al.\"}\n",
    "}\n",
    "\n",
    "# This query will filter documents that have a title starting with \"Comet\"\n",
    "prefix_query = {\n",
    "    \"prefix\": {\"title.keyword\": \"Comet\"}\n",
    "}\n",
    "\n",
    "\n",
    "print(\"=== Term Query on date ===\")\n",
    "res = es.search(index=index_name, body={\"query\": {\"bool\": {\"filter\": [term_query]}}})\n",
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    pprint(hit[\"_source\"])\n",
    "\n",
    "print(\"\\n=== Range Query on date ===\")\n",
    "res = es.search(index=index_name, body={\"query\": {\"bool\": {\"filter\": [range_query]}}})\n",
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    pprint(hit[\"_source\"])\n",
    "\n",
    "print(\"\\n=== Exists Query on note ===\")\n",
    "res = es.search(index=index_name, body={\"query\": {\"bool\": {\"filter\": [exists_query]}}})\n",
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    pprint(hit[\"_source\"])\n",
    "\n",
    "print(\"\\n=== Exact Term Query on authors ===\")\n",
    "res = es.search(index=index_name, body={\"query\": {\"bool\": {\"filter\": [term_authors_query]}}})\n",
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    pprint(hit[\"_source\"])\n",
    "\n",
    "print(\"\\n=== Prefix Query on title ===\")\n",
    "res = es.search(index=index_name, body={\"query\": {\"bool\": {\"filter\": [prefix_query]}}})\n",
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    pprint(hit[\"_source\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Must requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The must criterion works much like filter in that it first determines which records are eligible but with one key difference: when a document matches a must clause, its relevance score is increased. You can include multiple must clauses, and they’re combined with a logical AND (i.e., a document must satisfy all of them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "must_title = {\n",
    "    \"match\": {\"title\": \"Comet\"}\n",
    "}\n",
    "\n",
    "must_explanation = {\n",
    "    \"match\": {\"explanation\": \"nebula\"}\n",
    "}\n",
    "\n",
    "print(\"=== Must: Title Contains 'light' (size=2) ===\")\n",
    "res = es.search(\n",
    "    index=index_name,\n",
    "    # The size parameter limits the number of results returned. Default is 10.\n",
    "    body={\n",
    "        \"size\": 2,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [must_title]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    print(f\"_score={hit['_score']:.2f}\")\n",
    "    pprint(hit[\"_source\"])\n",
    "\n",
    "\n",
    "print(\"\\n=== Must: Title Contains 'Comet' AND Explanation Contains 'nebula' (size=2) ===\")\n",
    "res = es.search(\n",
    "    index=index_name,\n",
    "    body={\n",
    "        \"size\": 2,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    must_title,\n",
    "                    must_explanation\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    print(f\"_score={hit['_score']:.2f}\")\n",
    "    pprint(hit[\"_source\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first query, you’ll notice the first document’s _score is higher than the second’s—clearly demonstrating how the must clause impacts relevance scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Must_not requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although its name might imply the opposite of must, must_not actually behaves like a negated filter. Any document that matches a must_not clause is simply removed from the set of candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "must_not_image = {\n",
    "    \"exists\": {\"field\": \"image_url\"}\n",
    "}\n",
    "\n",
    "print(\"=== Example 1: must_not exists image_url (size=2) ===\")\n",
    "res1 = es.search(\n",
    "    index=index_name,\n",
    "    body={\n",
    "        \"size\": 2,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must_not\": [must_not_image]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "for hit in res1[\"hits\"][\"hits\"]:\n",
    "    pprint(hit[\"_source\"])\n",
    "\n",
    "\n",
    "filter_date = {\n",
    "    \"range\": {\n",
    "        \"date\": {\"gte\": \"2024-09-09\", \"lte\": \"2024-09-30\"}\n",
    "    }\n",
    "}\n",
    "must_not_comet = {\n",
    "    \"prefix\": {\"title.keyword\": \"Comet\"}\n",
    "}\n",
    "\n",
    "print(\"\\n=== Example 2: range on date AND must_not prefix 'Comet' (size=2) ===\")\n",
    "res2 = es.search(\n",
    "    index=index_name,\n",
    "    body={\n",
    "        \"size\": 2,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"filter\":   [filter_date],\n",
    "                \"must_not\": [must_not_comet]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "for hit in res2[\"hits\"][\"hits\"]:\n",
    "    # Only docs from 2024-09-27 whose title does NOT start with \"Comet\"\n",
    "    pprint(hit[\"_source\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Should requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The should clause in a bool query implements a logical OR across its clauses:\n",
    "\n",
    "1. **Standalone should (no must clauses)**  \n",
    "   - A document only needs to match at least one should clause to be included.\n",
    "\n",
    "2. **Combined must + should**  \n",
    "   - All must clauses still act as required filters that documents must satisfy every must.  \n",
    "   - Each should clause that matches simply boosts the document’s relevance score; non-matching should clauses do not exclude the document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query will filter documents that match at least one the specified conditions\n",
    "query1 = {\n",
    "    \"size\": 2,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                { \"match\": { \"title\": \"Comet\" } },\n",
    "                { \"match\": { \"explanation\": \"nebula\" } },\n",
    "                { \"match\": { \"authors\": \"David Martinez Delgado et al.\" } }\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=== Query 1: Standalone should (title OR explanation) ===\")\n",
    "res1 = es.search(index=index_name, body=query1)\n",
    "for hit in res1[\"hits\"][\"hits\"]:\n",
    "    print(f\"_score={hit['_score']:.2f}\")\n",
    "    pprint(hit[\"_source\"])\n",
    "\n",
    "\n",
    "# This query will filter documents that match the date \"2024-09-27\" and boost the score if the title or explanation matches\n",
    "query2 = {\n",
    "    \"size\": 2,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                { \"range\": { \"date\": { \"gte\": \"2024-09-20\", \"lte\": \"2024-09-30\" } } }\n",
    "            ],\n",
    "            \"should\": [\n",
    "                { \"match\": { \"title\": \"Comet\" } },\n",
    "                { \"match\": { \"explanation\": \"comet\" } }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n=== Query 2: must range 2024-09-20 to 2024-09-30 + should (boost if title/explanation) ===\")\n",
    "res2 = es.search(index=index_name, body=query2)\n",
    "for hit in res2[\"hits\"][\"hits\"]:\n",
    "    print(f\"_score={hit['_score']:.2f}\")\n",
    "    pprint(hit[\"_source\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you want to increase the relevance of certain documents, you attach a positive boost to your query clauses (for example, a match or term query) by adding a boost parameter—this simply multiplies that clause’s score contribution in the final _score. To softly penalize documents without filtering them out entirely, you use the boosting query: it takes a required positive query and a negative query, and for any document that matches the negative clause, it multiplies its overall score by a negative_boost factor (a value between 0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch('http://localhost:9200')\n",
    "index_name = \"apod\"\n",
    "\n",
    "# 1️⃣ Positive boost: increase score when explanation contains \"meteor\"\n",
    "#    Uses `boost` directly on a match query.\n",
    "print(\"=== Positive Boost: explanation contains 'meteor' (boost=2.0) ===\")\n",
    "pos_query = {\n",
    "    \"size\": 2,\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"explanation\": {\n",
    "                \"query\": \"meteor\",\n",
    "                \"boost\": 2.0      # positive boost on match\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "res = es.search(index=index_name, body=pos_query)\n",
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    print(f\"_score={hit['_score']:.2f}\") \n",
    "    pprint(hit[\"_source\"])\n",
    "\n",
    "# 2️⃣ Negative boost: de-emphasize docs where explanation contains \"comet\"\n",
    "#    Uses the boosting query with match_all as the positive clause.\n",
    "print(\"\\n=== Negative Boost: explanation contains 'comet' (negative_boost=0.5) ===\")\n",
    "neg_query = {\n",
    "    \"size\": 2,\n",
    "    \"query\": {\n",
    "        \"boosting\": {\n",
    "            \"positive\": { \"match_all\": {} },        # match everything\n",
    "            \"negative\": {                           # demote these\n",
    "                \"match\": { \"explanation\": \"comet\" }\n",
    "            },\n",
    "            \"negative_boost\": 0.5                   # reduce score by 50% on match\n",
    "        }\n",
    "    }\n",
    "}\n",
    "res = es.search(index=index_name, body=neg_query)\n",
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    print(f\"_score={hit['_score']:.2f}\")\n",
    "    pprint(hit[\"_source\"])\n",
    "\n",
    "# 3️⃣ Combined boost: promote \"meteor\" matches and demote \"comet\" matches\n",
    "print(\"\\n=== Combined Boost: +2.0 for 'meteor', -0.5 for 'comet' ===\")\n",
    "both_query = {\n",
    "    \"size\": 2,\n",
    "    \"query\": {\n",
    "        \"boosting\": {\n",
    "            \"positive\": {\n",
    "                \"match\": {\n",
    "                    \"explanation\": {\n",
    "                        \"query\": \"meteor\",\n",
    "                        \"boost\": 2.0\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"negative\": {\n",
    "                \"match\": {\n",
    "                    \"explanation\": \"comet\"\n",
    "                }\n",
    "            },\n",
    "            \"negative_boost\": 0.5\n",
    "        }\n",
    "    }\n",
    "}\n",
    "res = es.search(index=index_name, body=both_query)\n",
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    print(f\"_score={hit['_score']:.2f}\")\n",
    "    pprint(hit[\"_source\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a id=\"freecodecamp\"></a> [Elasticsearch Course for Beginners - FreeCodeCamp](https://www.youtube.com/watch?v=a4HBKEda_F8&ab_channel=freeCodeCamp.org)\n",
    "\n",
    "2. <a id=\"elasticdoc\"></a> [Elastic Official Documentation](https://www.elastic.co/docs/get-started)\n",
    "\n",
    "3. <a id=\"elasticlab\"></a> [Elastic Search Lab - Tutorials](https://www.elastic.co/search-labs/tutorials)\n",
    "\n",
    "4. <a id=\"elasticlabBoolQueries\"> [Elastic Search Lab - Tutortial - Filters](https://www.elastic.co/search-labs/tutorials/search-tutorial/full-text-search/filters)\n",
    "\n",
    "5. <a id=\"elasticscore\"></a> [Elastic Search Lab - Understanding Elasticsearch scoring and the Explain API](https://www.elastic.co/search-labs/blog/elasticsearch-scoring-and-explain-api)\n",
    "\n",
    "6. <a id=\"mustnot\"></a> [Soumendra - Stack Overflow - Difference between must_not and filter in elasticsearch](https://stackoverflow.com/questions/47226479/difference-between-must-not-and-filter-in-elasticsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and Work Distribution\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
