{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring ElasticSearch\n",
    "\n",
    "**Mehdi Boustani** - S221594  \n",
    "**Nicolas Schneiders** - S203005  \n",
    "**Maxim Piron** - S211493  \n",
    "**Andreas Stistrup** - S212891  \n",
    "\n",
    "*Faculty of Applied Sciences, University of Liège*\n",
    "\n",
    "April 28, 2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In today’s digital world, users interact with vast amounts of data through search interfaces—whether it's browsing e-commerce platforms, reading documentation, or exploring media archives. They expect search engines to return accurate, relevant results instantly, even when queries include misspellings, vague phrasing, or synonyms. These expectations have grown alongside the exponential increase in the volume, variety, and velocity of data generated across platforms and applications.\n",
    "\n",
    "This surge in data (structured, semi-structured, and unstructured) presents a major challenge. Traditional relational databases, while excellent for transactional operations and structured data storage, are ill-suited for flexible, large-scale search. Their rigid schemas, exact-match query requirements, and vertical scaling limitations make them inadequate for handling modern search demands, especially when working with diverse data types like JSON, logs, and text-heavy content.\n",
    "\n",
    "This is where Elasticsearch comes in. Elasticsearch is a powerful, open-source, distributed search and analytics engine designed to operate at scale with low latency. It is built on top of Apache Lucene, and provides robust full-text search capabilities, fault-tolerant horizontal scalability, and a flexible document-based data model. Its ability to handle fuzzy matching, relevance scoring, autocomplete, and real-time analytics makes it a core component of many data-driven applications.\n",
    "\n",
    "Unlike traditional SQL-based systems, Elasticsearch uses a schema-free JSON format for indexing and querying, allowing for more dynamic data ingestion and flexible exploration. Features like match, fuzzy match, and filtering mechanisms allow users to retrieve relevant information, even in the presence of errors or ambiguous input, while keeping response times fast and consistent.\n",
    "\n",
    "In this tutorial, we will introduce the core concepts of Elasticsearch, walk through its installation and setup, and demonstrate how to import and query data using real-world examples. Along the way, we’ll highlight key features such as full-text search, filtering, boosting, and aggregations, and also explore its limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-life use cases\n",
    "\n",
    "Elasticsearch is widely adopted across industries for its efficiency, scalability, and flexibility in handling large volumes of data. Here are some common real-world applications:\n",
    "\n",
    "### E-commerce/Product Catalog Search\n",
    "Elasticsearch powers fast, relevant, and up-to-date results in e-commerce product searches, supporting faceted navigation. This requires inventory synchronization, user behavior tracking, and results caching.\n",
    "\n",
    "- [Netflix - Elasticsearch Indexing Strategy in Asset Management Platform](https://netflixtechblog.com/elasticsearch-indexing-strategy-in-asset-management-platform-amp-99332231e541) (article)\n",
    "- [eBay - Elasticsearch as a Service](https://www.elastic.co/elasticon/conf/2017/sf/elasticsearch-as-a-service-at-ebay) (webinar)\n",
    "- [Ticketmaster - Revolutionizing the Fan Experience with Search](https://www.elastic.co/elasticon/tour/2017/los-angeles/revolutionizing-the-fan-experience-with-search-at-ticketmaster) (webinar)\n",
    "- [BMW - BMW picks Elastic to drive new marketing and sales strategies](https://www.elastic.co/customers/bmw) (case study)\n",
    "\n",
    "### Workplace/Knowledge Base Search\n",
    "In enterprise settings, Elasticsearch enables efficient searching across various data sources while enforcing permissions. It integrates with third-party connectors, ensures document-level security, and supports role-based access.\n",
    "\n",
    "- [Airbus - Airbus ADNS: Powering the Search for Near Real-Time Access to Aircraft Technical Documents](https://www.elastic.co/customers/airbus) (case study)\n",
    "- [Pfizer - Elastic as a Fundamental Core to Pfizer’s Scientific Data Cloud](https://www.elastic.co/elasticon/tour/2019/boston/elastic-as-a-fundamental-core-to-pfizers-scientific-data-cloud) (webinar)\n",
    "\n",
    "### Website Search\n",
    "Website search functionality is enhanced with Elasticsearch for delivering relevant, up-to-date results. It involves web crawling, incremental indexing, and query caching.\n",
    "\n",
    "- [Github - Accelerating software development](https://www.elastic.co/customers/github) (case study)\n",
    "- [Wikimedia - Navigating the World's Encyclopedia](https://www.elastic.co/elasticon/conf/2015/sf/navigating-through-worlds-encyclopedia) (webinar)\n",
    "- [City of Portland - Better Search Means Happier Portlanders](https://www.elastic.co/customers/city-of-portland) (case study)\n",
    "\n",
    "### Customer Support Search\n",
    "Elasticsearch is used to surface relevant solutions and manage customer support queries, with features such as knowledge graphs, role-based access, and analytics tracking.\n",
    "\n",
    "- [AirBnB - How Airbnb manages to monitor customer issues at scale](https://medium.com/airbnb-engineering/how-airbnb-manages-to-monitor-customer-issues-at-scale-b883301ca461) (article)\n",
    "- [Shopify - Powering the search for better help documentation](https://www.elastic.co/customers/shopify) (case study)\n",
    "\n",
    "### Chatbots and Retrieval-Augmented Generation (RAG)\n",
    "Elasticsearch supports chatbots and RAG applications by enabling natural conversations, providing context, and maintaining knowledge. It leverages vector search, machine learning models, and knowledge base integration.\n",
    "\n",
    "- [Stack Overflow - Stack Overflow rolls out generative AI using Elasticsearch and Azure Open AI](https://www.elastic.co/customers/stack-overflow) (case study)\n",
    "\n",
    "### Geospatial Search\n",
    "Geospatial search in Elasticsearch handles location-based queries, sorts results by proximity, and filters by area. It utilizes geo-mapping, spatial indexing, and distance calculations.\n",
    "\n",
    "- [Uber - Engineering Uber Predictions in Real Time with ELK](https://www.uber.com/en-BE/blog/elk/) (article)\n",
    "- [Google, Yelp, Zamato - Find Nearby Businesses: Geospatial Index](https://medium.com/@jagriti.bansal/how-google-search-yelp-zomato-find-nearby-businesses-geospatial-index-06c78f4f935b) (article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How ElasticSearch works\n",
    "\n",
    "## Data format\n",
    "ElasticSearch manipulates data in the form of indexes, documents, and fields. These are the equivalent of databases, rows, and columns inin traditional SQL-based databases management systems. The data is stored as JSON files, which allows ElasticSearch to have a flexible schema.\n",
    "\n",
    "## Distributed systems\n",
    "Since ElasticSearch is built to work on distributed systems at its core, it utilizes clusters (groups of machines), nodes (machines), and shards (pieces of indexes).\n",
    "\n",
    "Sharding is done by splitting each index into multiple parts called shards, which are distributed across different nodes in the cluster. Each shard is a fully functional Lucene index that can be searched and queried independently. When a document is indexed, Elasticsearch uses a hashing algorithm on the document’s ID to determine which primary shard it should be stored in. Replica shards are also created for fault tolerance and load balancing.\n",
    "\n",
    "There are two types of shards: primaries and replicas. Each document in an index belongs to one primary shard. A replica shard is a copy of a primary shard. Replicas maintain redundant copies of data across the nodes in a cluster. This protects against hardware failure and increases capacity to serve read requests like searching or retrieving a document.\n",
    "\n",
    "Entire documents are sharded according to their document ID. The ID is hashed and then the hash modulo number of shards determines which primary shard receives the document.\n",
    "\n",
    "This allows Elasticsearch to scale horizontally, meaning that adding more nodes to the cluster can distribute data and workload more effectively, leading to better performance, fault tolerance, and high availability.\n",
    "\n",
    "## Representational Sate Transfer (REST)\n",
    "ElasticSearch follows the REST convention, which means that:\n",
    "- It is stateless: Each request from the client to the server must contain all the information needed to understand and process the request.\n",
    "- It follows a client-server model: The client (such as Kibana or an HTTP client) sends requests to the server (Elasticsearch), which processes and returns responses.\n",
    "- It has a uniform interface: Standard HTTP methods like `GET`, `POST`, `PUT`, and `DELETE` are used to perform actions on resources (e.g., documents or indexes).\n",
    "- It is resource-based: Data is organized and accessed via URLs that represent resources (e.g., `/my_index/_doc/1` represents document ID 1 in the index `my_index`).\n",
    "\n",
    "## Domain Specific Language (DSL)\n",
    "Elasticsearch uses its own Domain Specific Language (DSL) for querying and manipulating data. This JSON-based query language allows users to build rich and expressive queries to filter, sort, aggregate, and search data.\n",
    "\n",
    "DSL is structured in a way that enables:\n",
    "- Full-text search\n",
    "- Structured filtering\n",
    "- Complex aggregations (like averages, histograms, and term counts)\n",
    "- Boolean logic (`must`, `should`, `must_not`)\n",
    "- Nested and range queries\n",
    "\n",
    "This powerful query language is a key feature that distinguishes Elasticsearch from traditional databases, making it ideal for full-text search, analytics, and log aggregation use cases.\n",
    "\n",
    "## Inverted indexes\n",
    "An inverted index is a core data structure used by Elasticsearch to enable fast and efficient full-text searches.\n",
    "\n",
    "An inverted index can be comapred to the index at the back of a book:\n",
    "- A regular (forward) index maps documents to the words (terms) they contain.\n",
    "- An inverted index maps each word (term) to the list of documents that contain it.\n",
    "\n",
    "An inverted index is composed of:\n",
    "1. A term dictionary that maps terms to postings lists, implemented as a [finite state transducer](https://en.wikipedia.org/wiki/Finite-state_transducer);\n",
    "2. Postings lists which are lists of document IDs in which the terms appear. There is additional metadata associated with the document IDs, such as:\n",
    "    - Term frequency: How often the term appears in each document.\n",
    "    - Positions: The positions within the document where the term appears (for phrase queries).\n",
    "    - Offsets: Byte offsets in the text.  \n",
    "\n",
    "This reversal allows ElasticSearch to quickly find all documents that match a search term.\n",
    "\n",
    "## Relevance scoring\n",
    "ElasticSearch outputs results based on relevance. The relevance score is computed using the following function:\n",
    "\n",
    "$$\n",
    "\\text{score}(D, T) = \\sum_{i=1}^{n} \\text{IDF}(t_i) \\cdot \\frac{f(t_i, D) \\cdot (k_1 + 1)}{f(t_i, D) + k_1 \\cdot \\left(1 - b + b \\cdot \\frac{|D|}{\\text{avgdl}}\\right)}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $D$ is the document being scored;\n",
    "- $T$ is the list of tokens of the query;\n",
    "- $IDF$ is the inverse document frequency (measures how frequent a term is across all documents);\n",
    "- $f(t_i, D)$ is the term frequency within $D$;\n",
    "- $k_1$ is a parameter controlling how much the term frequency affects the score;\n",
    "- $b$ is a normalization parameter controlling how much document length affects the score;\n",
    "- $avgdl$ is the average document length.\n",
    "\n",
    "This ranking function is based on the [Okapi BM25](https://en.wikipedia.org/wiki/Okapi_BM25) ranking function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation & configuration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing ElasticSearch[<sup>1</sup>](#elasticlab)\n",
    "If you don't have Docker installed yet, you can download and install it from the [official website](https://www.docker.com/). \n",
    "\n",
    "Once Docker is running on your machine, launch ElasticSearch using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -p 127.0.0.1:9200:9200 -d --name elasticsearch \\\n",
    "  -e \"discovery.type=single-node\" \\\n",
    "  -e \"xpack.security.enabled=false\" \\\n",
    "  -e \"xpack.license.self_generated.type=trial\" \\\n",
    "  -v \"elasticsearch-data:/usr/share/elasticsearch/data\" \\\n",
    "  docker.elastic.co/elasticsearch/elasticsearch:8.15.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies  \n",
    "Let's install all the necessary Python packages we'll be using throughout this tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests       → to interact with the ElasticSearch REST API\n",
    "# elasticsearch  → official ElasticSearch Python client\n",
    "\n",
    "!pip install requests elasticsearch==8.15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from elasticsearch import ElasticSearch, helpers\n",
    "\n",
    "es = ElasticSearch('http://localhost:9200')\n",
    "info = es.info()\n",
    "\n",
    "print('Connected to ElasticSearch !')\n",
    "pprint(info.body)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data with the bulk api\n",
    "\n",
    "To efficiently load a large dataset[<sup>2</sup>](#freecodecamp) into ElasticSearch, we use the Bulk API. This method allows us to insert multiple documents in a single request, which is much faster and more efficient than indexing documents one by one. In this example, we will import the contents of our `apod.json` file—where each element is a document—into a new index called `apod`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Open the file\n",
    "with open(\"apod.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Prepare the actions for the bulk\n",
    "actions = [\n",
    "    {\n",
    "        \"_index\": \"apod\",\n",
    "        \"_id\": doc[\"title\"], # We use the title as index since it is a unique field (the unicity is important!)\n",
    "        \"_source\": doc\n",
    "    }\n",
    "    for doc in data\n",
    "]\n",
    "\n",
    "# We import the data in bulk\n",
    "try:\n",
    "    helpers.bulk(es, actions)\n",
    "    print(\"Bulk import terminé !\")\n",
    "except  Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic queries in ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ElasticSearch exposes a RESTful API, which means you interact with it using standard HTTP methods. Here are the most common operations:\n",
    "\n",
    "- **GET**: Read a document or perform a search\n",
    "- **POST**: Add a new document\n",
    "- **PUT**: Create or replace a document or an index\n",
    "- **DELETE**: Remove a document or an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET method\n",
    "\n",
    "The GET method is used to retrieve data from our json file by providing an id. If the document with the specified id doesn't exist, it throws an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    doc = es.get(index=\"apod\", id=\"A Hazy Harvest Moon\")\n",
    "    pprint(doc['_source'])\n",
    "\n",
    "except:\n",
    "    print(\"A document with this id doesn't exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST method\n",
    "\n",
    "The POST method is used to create a new document. When using the index() method without specifying an id, elasticsearch automatically generates one (not the title as the other documents). The POST method is \"hidden\" behind the index method of the elasticsearch python client (same for the PUT method detailed after)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "new_id = \"A New APOD\"\n",
    "\n",
    "new_doc = {\n",
    "    \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"title\": new_id,\n",
    "    \"explanation\": \"This is a new document added via POST.\",\n",
    "    \"image_url\": \"https://apod.nasa.gov/apod/image/2410/new_apod.jpg\",\n",
    "    \"authors\": \"Mehdi Boustani\"\n",
    "}\n",
    "\n",
    "res = es.index(index=\"apod\", document=new_doc)\n",
    "\n",
    "print(\"Document added successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PUT method\n",
    "\n",
    "The PUT method is used to create or replace a document at a specified id. If a document with that id already exists, it will be overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_id = \"Replaced APOD\"\n",
    "\n",
    "doc = {\n",
    "    \"date\": \"2024-10-02\",\n",
    "    \"title\": replaced_id,\n",
    "    \"explanation\": \"This document replaces any previous one with the same ID.\",\n",
    "    \"image_url\": \"https://apod.nasa.gov/apod/image/2410/new_apod.jpg\",\n",
    "    \"authors\": \"Mehdi Boustani\"\n",
    "}\n",
    "\n",
    "# Let's replace our previously created document\n",
    "es.index(index=\"apod\", id=doc[\"title\"], document=doc)\n",
    "\n",
    "print(f\"Document with id '{new_id}' replaced by a new document with id '{replaced_id}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DELETE method\n",
    "\n",
    "This method is used to delete a document by its id. The id must be known and specified in the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    es.delete(index=\"apod\", id=replaced_id)\n",
    "    print(f\"Document with ID {replaced_id} deleted.\")\n",
    "\n",
    "except:\n",
    "    print(\"The specified document to delete doesn't exist\")\n",
    "\n",
    "# Delete the entire index (be careful, this is command is irreversible)\n",
    "# es.indices.delete(index=\"apod\")\n",
    "# print(\"Index 'apod' deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSL vs SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ElasticSearch doesn't use traditional SQL language to query data, but rather a **DSL (Domain Specific Language)** based on JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main differencies\n",
    "\n",
    "1. **Query Structure**\n",
    "   - **SQL**: Uses a strict syntax with clauses like `SELECT`, `FROM`, `WHERE`\n",
    "   - **DSL**: Uses a nested JSON format, offering more flexibility in how queries are expressed\n",
    "\n",
    "2. **Search Types**\n",
    "   - **SQL**: Focuses mainly on exact matches\n",
    "   - **DSL**: Supports advanced search techniques like full-text search, fuzzy matching, and range queries\n",
    "\n",
    "Let's explore practical examples comparing SQL concepts with ElasticSearch's DSL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full-text search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"title\": \"moon\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=\"apod\", body=query)\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SQL equivalent:** `SELECT * FROM apod WHERE title LIKE '%moon%'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact match with term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"term\": {\n",
    "            \"title.keyword\": {\n",
    "                \"value\": \"A Hazy Harvest Moon\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=\"apod\", body=query)\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_source\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SQL equivalent:** `SELECT * FROM apod WHERE title = 'A Hazy Harvest Moon'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Range Query (Numeric/date filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We filter documents by a date range\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"range\": {\n",
    "            \"date\": {\n",
    "                \"gte\": \"2020-01-01\",\n",
    "                \"lte\": \"2020-01-15\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=\"apod\", body=query)\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_source\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SQL equivalent:** `SELECT * FROM apod WHERE date BETWEEN '2020-01-01' AND '2020-12-31'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy Query (Typo-tolerant search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typo-tolerant search with fuzzy\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"fuzzy\": {\n",
    "            \"title\": {\n",
    "                \"value\": \"Galaxi\",\n",
    "                \"fuzziness\": \"AUTO\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=\"apod\", body=query)\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SQL equivalent:** No direct equivalent, similar to a `LIKE` with typos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticSearch as a search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of ElasticSearch is to empower client workflows to retrieve data from your database using powerful, flexible queries. To customize search behavior, ElasticSearch offers several fine-tuning parameters. In this section, we’ll explore the filter, must, must_not, and should clauses.\n",
    "\n",
    "A key concept here is document scoring. When you run a query, ElasticSearch calculates a relevance score for each candidate document and orders results accordingly. Then, it returns the top n documents based on that ranking. To further control how scores influence ordering, you can use the boost parameter to adjust relevance and achieve custom ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you apply a filter criterion to your query, you define one or more clauses that documents must satisfy to be included. Filters are score-neutral, they don’t alter a document’s relevance score, they only prune out non-matching hits. Below we’ll explore a selection of the most common filter clauses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"apod\"\n",
    "\n",
    "queries = []\n",
    "\n",
    "# This query will filter out documents that do not match the date \"2024-09-27\"\n",
    "term_query = {\n",
    "    \"term\": {\"date\": \"2024-09-27\"}\n",
    "}\n",
    "queries.append((\"=== Term Query on date ===\", term_query))\n",
    "\n",
    "# This query will filter documents with a date between \"2024-09-09\" and \"2024-09-30\"\n",
    "range_query = {\n",
    "    \"range\": {\n",
    "        \"date\": {\"gte\": \"2024-09-09\", \"lte\": \"2024-09-30\"}\n",
    "    }\n",
    "}\n",
    "queries.append((\"=== Range Query on date ===\", range_query))\n",
    "\n",
    "# This query will filter documents that have a non-null value for the field \"image_url\"\n",
    "exists_query = {\n",
    "    \"exists\": {\"field\": \"note\"}\n",
    "}\n",
    "queries.append((\"=== Exists Query on note ===\", exists_query))\n",
    "\n",
    "# This query will filter documents that have the exact term \"David Martinez Delgado et al.\" in the \"authors\" field\n",
    "term_authors_query = {\n",
    "    \"term\": {\"authors.keyword\": \"David Martinez Delgado et al.\\n\"}\n",
    "}\n",
    "queries.append((\"=== Exact Term Query on authors ===\", term_authors_query))\n",
    "\n",
    "# This query will filter documents that have a title starting with \"Comet\"\n",
    "prefix_query = {\n",
    "    \"prefix\": {\"title.keyword\": \"Comet\"}\n",
    "}\n",
    "queries.append((\"=== Prefix Query on title ===\", prefix_query))\n",
    "\n",
    "\n",
    "for title, query in queries:\n",
    "    print(title)\n",
    "    response = es.search(index=index_name, body={\"query\": {\"bool\": {\"filter\": [query]}}})\n",
    "    for hit in response[\"hits\"][\"hits\"]:\n",
    "        pprint(hit[\"_source\"])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Must requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The must criterion works much like filter in that it first determines which records are eligible but with one key difference: when a document matches a must clause, its relevance score is increased. You can include multiple must clauses, and they are combined with a logical AND (i.e., a document must satisfy all of them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "must_title = {\n",
    "    \"match\": {\"title\": \"Comet\"}\n",
    "}\n",
    "\n",
    "must_explanation = {\n",
    "    \"match\": {\"explanation\": \"nebula\"}\n",
    "}\n",
    "\n",
    "print(\"=== Must: Title Contains 'Comet' (size=2) ===\")\n",
    "res = es.search(\n",
    "    index=index_name,\n",
    "    # The size parameter limits the number of results returned. Default is 10.\n",
    "    body={\n",
    "        \"size\": 2,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [must_title]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    print(f\"_score={hit['_score']:.2f}\")\n",
    "    pprint(hit[\"_source\"])\n",
    "\n",
    "\n",
    "print(\"\\n=== Must: Title Contains 'Comet' AND Explanation Contains 'nebula' (size=2) ===\")\n",
    "res = es.search(\n",
    "    index=index_name,\n",
    "    body={\n",
    "        \"size\": 2,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    must_title,\n",
    "                    must_explanation\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    print(f\"_score={hit['_score']:.2f}\")\n",
    "    pprint(hit[\"_source\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first query, you will notice the first document’s _score is higher than the second’s—clearly demonstrating how the must clause impacts relevance scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Must_not requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although its name might imply the opposite of must, must_not actually behaves like a negated filter. Any document that matches a must_not clause is simply removed from the set of candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "must_not_image = {\n",
    "    \"exists\": {\"field\": \"image_url\"}\n",
    "}\n",
    "\n",
    "print(\"=== Example 1: must_not exists image_url (size=2) ===\")\n",
    "res1 = es.search(\n",
    "    index=index_name,\n",
    "    body={\n",
    "        \"size\": 2,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must_not\": [must_not_image]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "for hit in res1[\"hits\"][\"hits\"]:\n",
    "    pprint(hit[\"_source\"])\n",
    "\n",
    "\n",
    "filter_date = {\n",
    "    \"range\": {\n",
    "        \"date\": {\"gte\": \"2024-09-09\", \"lte\": \"2024-09-30\"}\n",
    "    }\n",
    "}\n",
    "must_not_comet = {\n",
    "    \"prefix\": {\"title.keyword\": \"Comet\"}\n",
    "}\n",
    "\n",
    "print(\"\\n=== Example 2: range on date AND must_not prefix 'Comet' (size=2) ===\")\n",
    "res2 = es.search(\n",
    "    index=index_name,\n",
    "    body={\n",
    "        \"size\": 2,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"filter\":   [filter_date],\n",
    "                \"must_not\": [must_not_comet]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "for hit in res2[\"hits\"][\"hits\"]:\n",
    "    # Only docs from 2024-09-27 whose title does NOT start with \"Comet\"\n",
    "    pprint(hit[\"_source\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Should requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The should clause in a bool query implements a logical OR across its clauses:\n",
    "\n",
    "1. **Standalone should (no must clauses)**  \n",
    "   - A document only needs to match at least one should clause to be included.\n",
    "\n",
    "2. **Combined must + should**  \n",
    "   - All must clauses still act as required filters that documents must satisfy every must.  \n",
    "   - Each should clause that matches simply boosts the document’s relevance score; non-matching should clauses do not exclude the document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query will filter documents that match at least one the specified conditions\n",
    "query1 = {\n",
    "    \"size\": 2,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                { \"match\": { \"title\": \"Comet\" } },\n",
    "                { \"match\": { \"explanation\": \"nebula\" } },\n",
    "                { \"match\": { \"authors\": \"David Martinez Delgado et al.\" } }\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=== Query 1: Standalone should (title, explanation OR authors) ===\")\n",
    "res1 = es.search(index=index_name, body=query1)\n",
    "for hit in res1[\"hits\"][\"hits\"]:\n",
    "    print(f\"_score={hit['_score']:.2f}\")\n",
    "    pprint(hit[\"_source\"])\n",
    "\n",
    "\n",
    "# This query will filter documents that match the date \"2024-09-27\" and boost the score if the title or explanation matches\n",
    "query2 = {\n",
    "    \"size\": 2,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                { \"range\": { \"date\": { \"gte\": \"2024-09-20\", \"lte\": \"2024-09-30\" } } }\n",
    "            ],\n",
    "            \"should\": [\n",
    "                { \"match\": { \"title\": \"Comet\" } },\n",
    "                { \"match\": { \"explanation\": \"comet\" } }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n=== Query 2: must range 2024-09-20 to 2024-09-30 + should (boost if title/explanation) ===\")\n",
    "res2 = es.search(index=index_name, body=query2)\n",
    "for hit in res2[\"hits\"][\"hits\"]:\n",
    "    print(f\"_score={hit['_score']:.2f}\")\n",
    "    pprint(hit[\"_source\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you want to increase the relevance of certain documents in ElasticSearch, you can apply a boost factor to a query clause. If the clause is satisfied (i.e., it matches a document), its score contribution will be multiplied by the boost factor, increasing the document’s overall relevance in the results.\n",
    "\n",
    "However, if you want to decrease the relevance of certain documents (i.e., apply a *negative boost*), you need to use a boosting query. Boosting queries consist of two main components:\n",
    "\n",
    "- **`positive`**: the main query whose matches should be scored normally (and optionally boosted).\n",
    "- **`negative`**: a query whose matches should reduce the score of the document.\n",
    "\n",
    "Additionally, the query includes a **`negative_boost`** parameter, which controls how much the negative matches reduce the document’s final score. This value must be between `0` and `1`, where:\n",
    "\n",
    "- A value close to `0` significantly reduces the score of documents matching the negative clause.\n",
    "- A value of `1` means no penalty is applied.\n",
    "\n",
    "This mechanism is useful when you want to penalize certain documents without completely excluding them from the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Positive boost: increase score when explanation contains \"meteor\"\n",
    "#    Uses `boost` directly on a match query.\n",
    "print(\"=== Positive Boost: explanation contains 'meteor' (boost=2.0) ===\")\n",
    "pos_query = {\n",
    "    \"size\": 2,\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"explanation\": {\n",
    "                \"query\": \"meteor\",\n",
    "                \"boost\": 2.0      # positive boost on match\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "res = es.search(index=index_name, body=pos_query)\n",
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    print(f\"_score={hit['_score']:.2f}\") \n",
    "    pprint(hit[\"_source\"])\n",
    "\n",
    "# 2️⃣ Negative boost: de-emphasize docs where explanation contains \"comet\"\n",
    "#    Uses the boosting query with match_all as the positive clause.\n",
    "print(\"\\n=== Negative Boost: explanation contains 'comet' (negative_boost=0.5) ===\")\n",
    "neg_query = {\n",
    "    \"size\": 2,\n",
    "    \"query\": {\n",
    "        \"boosting\": {\n",
    "            \"positive\": { \"match_all\": {} },        # match everything\n",
    "            \"negative\": {                           # demote these\n",
    "                \"match\": { \"explanation\": \"comet\" }\n",
    "            },\n",
    "            \"negative_boost\": 0.5                   # reduce score by 50% on match\n",
    "        }\n",
    "    }\n",
    "}\n",
    "res = es.search(index=index_name, body=neg_query)\n",
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    print(f\"_score={hit['_score']:.2f}\")\n",
    "    pprint(hit[\"_source\"])\n",
    "\n",
    "# 3️⃣ Combined boost: promote \"meteor\" matches and demote \"comet\" matches\n",
    "print(\"\\n=== Combined Boost: +2.0 for 'meteor', -0.5 for 'comet' ===\")\n",
    "both_query = {\n",
    "    \"size\": 2,\n",
    "    \"query\": {\n",
    "        \"boosting\": {\n",
    "            \"positive\": {\n",
    "                \"match\": {\n",
    "                    \"explanation\": {\n",
    "                        \"query\": \"meteor\",\n",
    "                        \"boost\": 2.0\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"negative\": {\n",
    "                \"match\": {\n",
    "                    \"explanation\": \"comet\"\n",
    "                }\n",
    "            },\n",
    "            \"negative_boost\": 0.5\n",
    "        }\n",
    "    }\n",
    "}\n",
    "res = es.search(index=index_name, body=both_query)\n",
    "for hit in res[\"hits\"][\"hits\"]:\n",
    "    print(f\"_score={hit['_score']:.2f}\")\n",
    "    pprint(hit[\"_source\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will dive into a handful of Elasticsearch’s most powerful advanced features. While ElasticSearch offers a wealth of capabilities beyond what we cover here, the three topics we’ll focus on are:\n",
    "\n",
    "- **Aggregations**: Real-time analytics and data summarization  \n",
    "- **Highlighting**: Extracting and emphasizing matching text snippets  \n",
    "- **Autocomplete**: Instant-search experiences via suggesters and search-as-you-type  \n",
    "\n",
    "Each feature can be mixed and matched or extended with dozens of other ElasticSearch tools to build rich, high-performance search applications tailored to your needs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation queries don’t return individual documents, instead, they compute analytics over the set of matched records. ElasticSearch supports three main aggregation types:\n",
    "\n",
    "- **Bucket aggregations** group documents into “buckets” based on shared values (e.g., terms, date intervals, numeric ranges, or histograms).  \n",
    "- **Metric aggregations** calculate statistics (such as count, sum, average, min/max) over those documents.  \n",
    "- **Pipeline aggregations** take the output of one or more aggregations and run further calculations on it, enabling you to chain operations together.\n",
    "\n",
    "In this tutorial, we will use those aggregations to show how you can both segment your data and then perform successive analyses on those segments.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to get the number of documents per month\n",
    "# To do so, we will use a date_histogram aggregation to group documents by month\n",
    "# and a cumulative_sum aggregation to get the cumulative count of documents over time.\n",
    "body = {\n",
    "    \"size\": 0,\n",
    "    \"aggs\": {\n",
    "        \"entries_per_month\": {\n",
    "            # Bucket agg that uses a date_histogram to group documents by month\n",
    "            \"date_histogram\": {\n",
    "                \"field\":             \"date\",\n",
    "                \"calendar_interval\": \"month\",\n",
    "                \"format\":            \"yyyy-MM\"\n",
    "            },\n",
    "            # Pipeline agg that calculates the cumulative sum of the monthly counts\n",
    "            \"aggs\": {\n",
    "                # Metric agg that counts the number of documents in each month\n",
    "                \"monthly_count\": {\n",
    "                    \"value_count\": { \"field\": \"date\" }\n",
    "                },\n",
    "                # Pipeline agg that calculates the cumulative sum of the monthly counts\n",
    "                \"cumulative_entries\": {\n",
    "                    \"cumulative_sum\": {\n",
    "                        \"buckets_path\": \"monthly_count\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=\"apod\", body=body)\n",
    "\n",
    "for bucket in response[\"aggregations\"][\"entries_per_month\"][\"buckets\"]:\n",
    "    month = bucket[\"key_as_string\"]\n",
    "    count = bucket[\"monthly_count\"][\"value\"]\n",
    "    cum   = bucket[\"cumulative_entries\"][\"value\"]\n",
    "    print(f\"{month} → count: {count}, cumulative: {cum}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highlighting in ElasticSearch works by surrounding each occurrence of a query term in your document text with customizable tags (by default <em>/</em>, but you can use any HTML or marker you like). When you include a highlight section in your search request, ElasticSearch will:\n",
    "\n",
    "1. Analyze the specified field(s) to find where your query terms fall.\n",
    "2. Extract short snippets (fragments) around each match.\n",
    "3. Wrap each matching term in your chosen pre_tags and post_tags.\n",
    "4. Return those snippets alongside each hit in a top-level highlight block.\n",
    "\n",
    "This makes it easy to show users exactly where and in what context—their search terms appeared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"explanation\": \"comet\"\n",
    "    }\n",
    "  },\n",
    "  \"highlight\": {\n",
    "    # Customize the highlight tags\n",
    "    \"pre_tags\":  [\"<mark>\"],\n",
    "    \"post_tags\": [\"</mark>\"],\n",
    "    # Specify in wich fields we want to highlight\n",
    "    \"fields\": {\n",
    "      \"explanation\": {\n",
    "        # This skip the fragmentation of the text and return the whole text with each match highlighted\n",
    "        \"number_of_fragments\": 0, \n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "response = es.search(index=\"apod\", body=query)\n",
    "\n",
    "print(\"=== Highlighted Results ===\")\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(f\"Title: {hit['_source']['title']}\")\n",
    "    print(\"Highlighted explanation:\")\n",
    "    for fragment in hit[\"highlight\"][\"explanation\"]:\n",
    "        print(fragment)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final feature we will cover is autocomplete. ElasticSearch offers four different approaches, but we will choose the simplest one with the least setup: the search-as-you-type mechanism.\n",
    "\n",
    "The first step is to reindex your data to add the field required for this feature (we could add it directly on our first index).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if es.indices.exists(index=\"apod_v2\"):\n",
    "    es.indices.delete(index=\"apod_v2\")  \n",
    "\n",
    "# New index mapping with search_as_you_type\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\n",
    "                \"type\":\"search_as_you_type\", # Enable autocomplete search\n",
    "                \"max_shingle_size\": 3\n",
    "            },\n",
    "            \"date\":        { \"type\": \"date\",   \"format\": \"yyyy-MM-dd\" },\n",
    "            \"explanation\": { \"type\": \"text\" },\n",
    "            \"image_url\":   { \"type\": \"keyword\" },\n",
    "            \"authors\":     { \"type\": \"text\" }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es.indices.create(index=\"apod_v2\", body=mapping)\n",
    "\n",
    "es.reindex(\n",
    "    body={\n",
    "        \"source\": { \"index\": \"apod\" },\n",
    "        \"dest\":   { \"index\": \"apod_v2\" }\n",
    "    },\n",
    "    wait_for_completion=True,\n",
    ")\n",
    "\n",
    "print(\"===Reindexing complete===\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate search-as-you-type in this notebook, we’ll embed an ipywidgets.Combobox as our search bar. Under the hood, each time you type a character, a tiny Python function sends a bool_prefix query to our search_as_you_type index and updates the dropdown with the matching titles. Note that you might need to press the enter key once to activate the search bar. You may need to restart your kernel in order for the search bar to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipywidgets jupyterlab_widgets                      \n",
    "%pip install jupyterlab\n",
    "!jupyter labextension install @jupyter-widgets/jupyterlab-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realized with the help of chatGPT\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Create the Search bar\n",
    "combo = widgets.Combobox(\n",
    "    placeholder='Type to search titles…',\n",
    "    options=[],\n",
    "    description='Search:',\n",
    "    ensure_option=False,\n",
    "    continuous_update=True\n",
    ")\n",
    "display(combo)\n",
    "\n",
    "last_call = 0\n",
    "lock = threading.Lock()\n",
    "\n",
    "def fetch_suggestions(text):\n",
    "    # ElasticSearch bool_prefix query against search-as-you-type\n",
    "    body = {\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": text,\n",
    "                \"type\":  \"bool_prefix\",\n",
    "                \"fields\": [\"title\",\"title._2gram\",\"title._3gram\"]\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"title\"],\n",
    "        \"size\": 5\n",
    "    }\n",
    "    resp = es.search(index=\"apod_v2\", body=body)\n",
    "    return [hit[\"_source\"][\"title\"] for hit in resp[\"hits\"][\"hits\"]]\n",
    "\n",
    "def on_value_change(change):\n",
    "    global last_call\n",
    "    value = change['new']\n",
    "    now = time.time()\n",
    "    with lock:\n",
    "        if now - last_call < 0.3:\n",
    "            return\n",
    "        last_call = now\n",
    "    if value:\n",
    "        combo.options = fetch_suggestions(value)\n",
    "    else:\n",
    "        combo.options = []\n",
    "\n",
    "combo.observe(on_value_change, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations of ElasticSearch\n",
    "One of the most commonly mentioned limitations in forums and blogs is that ElasticSearch performance and data durability can be heavily constrained by the resources allocated to the cluster. To maintain good performance and ensure data survivability, it may be necessary to increase the number of nodes and replicate data across them. This is not a technical limitation per se, but rather an infrastructure constraint that depends on available resources.\n",
    "\n",
    "From a technical standpoint, ElasticSearch is built on top of the **Lucene engine**, which is optimized for full-text search rather than relational queries such as joins or transactions. While ElasticSearch does offer limited support for join-like operations, they are far less powerful than those available in SQL databases and are typically very resource-intensive. As a result, these features are often disabled in production configurations.\n",
    "\n",
    "In terms of consistency, ElasticSearch follows an eventual consistency model rather than strong consistency. This means that in certain race conditions, inconsistencies in query results can occur shortly after data is written or updated.\n",
    "\n",
    "Although a portion of ElasticSearch is available for free, accessing the full feature set—particularly advanced security, monitoring, and machine learning capabilities—requires a paid license.\n",
    "\n",
    "Nevertheless, ElasticSearch remains one of the most powerful and widely adopted solutions for full-text search, offering high performance, scalability, and a rich query language. Its ability to index and search large volumes of textual data in near real-time makes it a strong choice for use cases such as log analytics, product search, and document indexing.\n",
    "\n",
    "Alternatives to ElasticSearch include **Apache Solr**, which is also built on Lucene and excels in traditional search applications, and **OpenSearch**, a community-driven fork of ElasticSearch that retains many of its features under a fully open-source license.\n",
    "\n",
    "### SQL for full-text search\n",
    "While many relational databases offer built-in full-text extensions, they remain fundamentally optimized for structured, transactional workloads rather than rich, large-scale text retrieval. Below are four core reasons why SQL full-text search falls short compared to ElasticSearch:\n",
    "\n",
    "#### 1. Limited Indexing Control & Analysis  \n",
    "- **Bolt-on inverted index**  \n",
    "  SQL full-text search layers an inverted index onto its B-tree/row-store engine, but provides virtually no knobs for customizing tokenization, stemming, or character filters.  \n",
    "- **Minimal analyzer pipelines**  \n",
    "  Text is split on whitespace/punctuation with fixed stemmers and stop-words—no pluggable analyzers, synonym maps, or language-specific processing as in ElasticSearch.  \n",
    "\n",
    "#### 2. Restricted Query & Search Features  \n",
    "- **Limited query operators**  \n",
    "  SQL full-text supports only Boolean operators (e.g., `CONTAINS`, `FREETEXT`) and basic proximity/NEAR clauses; there’s no built-in fuzzy, wildcard, regex, or span query support.  \n",
    "- **DIY fuzzy workarounds**  \n",
    "  To approximate typo-tolerance you must implement custom edit-distance functions or join strategies, which are far more complex and slower than Elasticsearch’s native fuzzy queries.  \n",
    "\n",
    "#### 3. Scalability & Distributed Architecture  \n",
    "- **Monolithic extension**  \n",
    "  Full-text runs in-process on your primary database server, limiting throughput under heavy search loads.  \n",
    "- **No native sharding/replication**  \n",
    "  ElasticSearch auto-shards, replicates, and rebalances indices across nodes; SQL Server or MySQL require manual partitioning or expensive clustering extensions to scale horizontally.\n",
    "\n",
    "### Comparison between relational Databases and ElasticSearch\n",
    "As with most decisions in technology, selecting the appropriate tools hinges on your specific use case. It's essential to assess the features you require, understand your typical workflows, and determine the data handling properties that are most critical for your operations. The following table provides a comparative overview of two prominent technologies, aiding in an informed decision-making process.\n",
    "\n",
    "| **Aspect**                | **ElasticSearch**                                                                                                                             | **MySQL**                                                                                                                       |\n",
    "|---------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Data Model**            | Document-oriented (NoSQL); stores data as JSON documents.                                                                                     | Relational (SQL); stores data in structured tables with predefined schemas.                                                     |\n",
    "| **Primary Use Cases**     | Full-text search, log and event data analysis, real-time analytics, and applications requiring complex search capabilities.                   | Transactional applications, structured data storage, and scenarios requiring complex joins and ACID compliance.                 |\n",
    "| **Query Language**        | ElasticSearch Query DSL (Domain Specific Language); designed for flexible and complex search operations.                                      | SQL (Structured Query Language); widely adopted for structured data querying and manipulation.                                  |\n",
    "| **Joins & Relationships** | Limited support for joins; alternatives like nested documents and parent-child relationships exist but can be complex and resource-intensive. | Robust support for joins, foreign keys, and complex relational queries.                                                         |\n",
    "| **Schema Flexibility**    | Schema-less; allows dynamic mapping, making it adaptable to varying data structures.                                                          | Schema-based; requires predefined schemas, offering strict data validation and integrity.                                       |\n",
    "| **Consistency Model**     | Eventually consistent; suitable for scenarios where immediate consistency is not critical.                                                    | Strong consistency with ACID (Atomicity, Consistency, Isolation, Durability) properties, ensuring reliable transactions.        |\n",
    "| **Scalability**           | Horizontally scalable; designed to handle large volumes of data across distributed systems.                                                   | Vertically scalable; can be scaled horizontally with additional configurations but is primarily optimized for vertical scaling. |\n",
    "| **Performance**           | Optimized for search operations; excels in scenarios requiring rapid full-text search and analytics.                                          | Optimized for transactional operations; performs well in scenarios requiring complex transactions and data integrity.           |\n",
    "| **Security Features**     | Basic security features available; advanced features like role-based access control and encryption are part of the commercial offerings.      | Offers robust security features, including user authentication, SSL support, and role-based access control.                     |\n",
    "| **Licensing**             | Open-source with a dual license model; some advanced features require a commercial license.                                                   | Open-source (GPL) with commercial support available; widely adopted and supported by a large community.                         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We began this tutorial by introducing the goals of ElasticSearch and how it leverages complex indexing mechanisms to deliver high performance and scalability. We also provided a brief recap of what indexes are, how they are used in relational databases, and the limitations and performance costs they can introduce.\n",
    "\n",
    "As we progressed, we walked through setting up an ElasticSearch cluster using Docker, connecting to it, and uploading bulk data. We then explored the basic API operations for document manipulation by ID and highlighted the differences between Query DSL and SQL. From there, we reviewed a broad range of advanced query types and features specifically tailored for building powerful search engine experiences.\n",
    "\n",
    "Using ElasticSearch proved to be quite intuitive. Even though we only covered a subset of its capabilities, it quickly became clear how the technology fits into real-world applications. Along the way, we encountered many configuration parameters that allow you to fine-tune ElasticSearch's behavior to meet specific needs.\n",
    "\n",
    "While ElasticSearch excels at full-text search, it may require more resources than a traditional database system. We also noted that its eventual consistency model differs from conventional databases, making it less suitable for some workflows. Nevertheless, if your application requires a robust and flexible full-text search engine, ElasticSearch is one of the most powerful solutions available, thanks to its rich feature set and high configurability.\n",
    "\n",
    "By following this tutorial, you should now have the knowledge and skills to build your first search engine application. With a thoughtfully designed search interface and parameterized queries, you can now deliver accurate and relevant results to your users efficiently and effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a id=\"elasticlab\"></a> [Elastic Search Lab - Tutorials](https://www.elastic.co/search-labs/tutorials)\n",
    "\n",
    "2. <a id=\"freecodecamp\"></a> [ElasticSearch Course for Beginners - FreeCodeCamp](https://www.youtube.com/watch?v=a4HBKEda_F8&ab_channel=freeCodeCamp.org)\n",
    "\n",
    "3. <a id=\"elasticlabBoolQueries\"> [Elastic Search Lab - Tutortial - Filters](https://www.elastic.co/search-labs/tutorials/search-tutorial/full-text-search/filters)\n",
    "\n",
    "4. <a id=\"elasticscore\"></a> [Elastic Search Lab - Understanding ElasticSearch scoring and the Explain API](https://www.elastic.co/search-labs/blog/elasticsearch-scoring-and-explain-api)\n",
    "\n",
    "5. <a id=\"mustnot\"></a> [Soumendra - Stack Overflow - Difference between must_not and filter in elasticsearch](https://stackoverflow.com/questions/47226479/difference-between-must-not-and-filter-in-elasticsearch)\n",
    "\n",
    "6. <a id=\"aggregations\"></a> [logz.io - Daniel Berman - A Basic Guide To ElasticSearch Aggregations](https://logz.io/blog/elasticsearch-aggregations)\n",
    "\n",
    "7. <a id=\"highlighting\"></a> [Elastic Official Documentation - Highlighting](https://www.elastic.co/docs/reference/elasticsearch/rest-apis/highlighting)\n",
    "\n",
    "8. <a id=\"autocomplete\"></a> [Opster - Amit Khandelwal - ElasticSearch Autocomplete Search](https://opster.com/guides/elasticsearch/how-tos/elasticsearch-auto-complete-guide/)\n",
    "\n",
    "9. <a id=\"JoinQueries\"></a> [Elastic Official Documentation - Joining Queries](https://www.elastic.co/docs/reference/query-languages/query-dsl/joining-queries)\n",
    "\n",
    "10. <a id=\"ressourcesLimit\"></a> [Reddit - What are the limits of elastic search?](https://www.reddit.com/r/elasticsearch/comments/6xm8wv/what_are_the_limits_of_elastic_search/)\n",
    "\n",
    "11. <a id=\"ESalternative1\"></a> [sematext - 11 Alternatives to ElasticSearch, OpenSearch, and Solr](https://sematext.com/blog/elasticsearch-opensearch-solr-alternatives/)\n",
    "\n",
    "12. <a id=\"ESalternative2\"></a> [BIGDATA - ElasticSearch Alternatives - The Ultimate Guide](https://bigdataboutique.com/blog/elasticsearch-alternatives-the-ultimate-guide-59ad00)\n",
    "\n",
    "13. <a id=\"ESvsSQL1\"></a> [Medium - ElasticSearch vs. Traditional Databases: Diving into Elastic search's Strengths](https://medium.com/@rajeevprasanna/elasticsearch-vs-traditional-databases-diving-into-elastic-searchs-strengths-c6f55b9b449f)\n",
    "\n",
    "14. <a id=\"ESvsSQL2\"></a> [knowi - ElasticSearch vs. MySQL: What to Choose?](https://www.knowi.com/blog/elasticsearch-vs-mysql-what-to-choose/)\n",
    "\n",
    "15. <a id=\"ESvsSLQ3\"></a> [Airbyte - ElasticSearch vs SQL Server - Key Differences](https://airbyte.com/data-engineering-resources/elasticsearch-vs-sql-server)\n",
    "\n",
    "16. <a id=\"TableGen\"></a> [Table Generator](https://www.tablesgenerator.com/markdown_tables)\n",
    "\n",
    "17. <a id=\"GPT\"></a> [ChatGPT](https://chatgpt.com/) was used to improve some sentences and to write some pieces of code.\n",
    "\n",
    "18. <a id=\"elasticdoc\"></a> [Elastic Official Documentation](https://www.elastic.co/docs/get-started)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and Work Distribution\n",
    "\n",
    "First, Nicolas researched some topics related to Elasticsearch. After discussing with the rest of the group to agree on the approach, Mehdi distributed the tasks equitably:\n",
    "\n",
    "- **Introduction, Real-world use cases and Explanation of ElasticSearch's workings**: Andreas\n",
    "- **Installation, Importing data with the bulk api (Dataset), DPL vs SQL and Basic queries in ElasticSearch**: Mehdi\n",
    "- **ElasticSearch as a search engine and Advanced features**: Nicolas\n",
    "- **Limitations of ElasticSearch and Conclusion**: Maxim\n",
    "\n",
    "After completing our respective sections, each member reviewed and improved on the work of others to ensure the overall correctness and coherence of the tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
