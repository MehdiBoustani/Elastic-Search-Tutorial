{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation & configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -p 127.0.0.1:9200:9200 -d --name elasticsearch \\\n",
    "  -e \"discovery.type=single-node\" \\\n",
    "  -e \"xpack.security.enabled=false\" \\\n",
    "  -e \"xpack.license.self_generated.type=trial\" \\\n",
    "  -v \"elasticsearch-data:/usr/share/elasticsearch/data\" \\\n",
    "  docker.elastic.co/elasticsearch/elasticsearch:8.15.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests       → to interact with the Elasticsearch REST API\n",
    "# elasticsearch  → official Elasticsearch Python client\n",
    "# pandas         → for handling and analyzing tabular data (e.g., dataset exploration)\n",
    "# matplotlib     → for optional data visualization (e.g., query stats or aggregations)\n",
    "\n",
    "!pip install requests elasticsearch==8.15.0 pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "es = Elasticsearch('http://localhost:9200')\n",
    "info = es.info()\n",
    "\n",
    "print('Connected to ElasticSearch !')\n",
    "pprint(info.body)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data with the bulk api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"apod.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Prepare the actions for the bulk\n",
    "actions = [\n",
    "    {\n",
    "        \"_index\": \"apod\",\n",
    "        \"_id\": doc[\"title\"], # We use the title as index since it is a unique field (the unicity is important!)\n",
    "        \"_source\": doc\n",
    "    }\n",
    "    for doc in data\n",
    "]\n",
    "\n",
    "# We import the data in bulk\n",
    "try:\n",
    "    helpers.bulk(es, actions)\n",
    "    print(\"Bulk import terminé !\")\n",
    "except  Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"title\": \"moon\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=\"apod\", body=query)\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_score\"], hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other types of match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"match_phrase\": {\n",
    "            \"title\": \"dark nebula\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=\"apod\", body=query)\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_score\"], hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"match_phrase\": {\n",
    "            \"title\": {\n",
    "                \"query\": \"dark nebula\",\n",
    "                \"slop\": 1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=\"apod\", body=query)\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_score\"], hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"match_phrase_prefix\": {\n",
    "            \"title\": \"dark neb\",\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=\"apod\", body=query)\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_score\"], hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"multi_match\": {\n",
    "            \"query\": \"Pyrenees\",\n",
    "            \"fields\": [\"title\", \"explanation\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=\"apod\", body=query)\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_score\"], hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typo-tolerant search with fuzzy\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"fuzzy\": {\n",
    "            \"title\": {\n",
    "                \"value\": \"Galaxi\",\n",
    "                \"fuzziness\": \"AUTO\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=\"apod\", body=query)\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_source\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ELEN0062",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
